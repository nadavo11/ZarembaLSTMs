{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM for time series prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-06T21:57:39.713714Z",
     "end_time": "2024-07-06T21:57:39.737870Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n",
    "we will train the LSTM model on the Penn  Treebank dataset. The Penn Treebank dataset is a dataset of cleaned and annotated English text. The data is split into training, validation, and testing sets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  no it was n't black monday \n",
      " but while the new york stock exchange did n't fall apart friday as the\n",
      "['no', 'it', 'was', \"n't\", 'black', 'monday', 'but', 'while', 'the', 'new']\n"
     ]
    }
   ],
   "source": [
    "train_data = open('data/ptb.train.txt', 'r').read()\n",
    "test_data = open('data/ptb.test.txt', 'r').read()\n",
    "valid_data = open('data/ptb.valid.txt', 'r').read()\n",
    "data = train_data + ' ' + test_data + ' ' + valid_data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-06T21:45:39.681036Z",
     "end_time": "2024-07-06T21:45:39.719658Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### let's see what are the most common words in the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.the: appears 59421 times\n",
      "2.<unk>: appears 53299 times\n",
      "3.N: appears 37607 times\n",
      "4.of: appears 28427 times\n",
      "5.to: appears 27430 times\n",
      "6.a: appears 24755 times\n",
      "7.in: appears 21032 times\n",
      "8.and: appears 20404 times\n",
      "9.'s: appears 11555 times\n",
      "10.for: appears 10436 times\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "leaderboard = Counter(data.split()).most_common(10)\n",
    "i = 0\n",
    "for word, freq in leaderboard:\n",
    "    i+=1\n",
    "    print(f'{i}.{word}: appears {freq} times')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenizing the data\n",
    "### create a vocabulary of words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_vocab(txt, max_vocab_size):\n",
    "    counter = Counter()\n",
    "    for t in txt:\n",
    "        counter.update(t.split())\n",
    "    most_common = counter.most_common(max_vocab_size - 1)\n",
    "    vocab = {word: idx + 1 for idx, (word, _) in enumerate(most_common)}\n",
    "    vocab['<unk>'] = 0\n",
    "    return vocab\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-06T21:46:17.340818Z",
     "end_time": "2024-07-06T21:46:17.365714Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# concatenate the data\n",
    "\n",
    "vocab = build_vocab(data, max_vocab_size=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-06T21:46:17.987585Z",
     "end_time": "2024-07-06T21:46:22.943077Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### create a function that converts a word to token index and vice versa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "\n",
    "# decode the token i to a word S\n",
    "def itos(i):\n",
    "    return list(vocab.keys())[i]\n",
    "\n",
    "# encode the word S to a token index i\n",
    "def stoi(s):\n",
    "    return vocab[s] if s in vocab else vocab['<unk>']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-06T21:46:59.939114Z",
     "end_time": "2024-07-06T21:46:59.985575Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "train_data = [stoi(word) for word in train_data.split()]\n",
    "valid_data = [stoi(word) for word in valid_data.split()]\n",
    "test_data = [stoi(word) for word in test_data.split()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-06T21:47:02.551317Z",
     "end_time": "2024-07-06T21:47:02.882756Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## build a dataset and dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_length = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-06T21:57:33.530089Z",
     "end_time": "2024-07-06T21:57:33.540132Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "class PTBDataset(Dataset):\n",
    "    def __init__(self, data, seq_length):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) // self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx * self.seq_length: (idx + 1) * self.seq_length]\n",
    "        y = self.data[idx * self.seq_length + 1: (idx + 1) * self.seq_length + 1]\n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "\n",
    "def batchify(data, batch_size, seq_length):\n",
    "    num_batches = len(data) // (batch_size * seq_length)\n",
    "    data = data[:num_batches * batch_size * seq_length]\n",
    "    data = np.reshape(data, [batch_size, -1])\n",
    "    return data\n",
    "\n",
    "train_data_batched = batchify(train_data, batch_size, seq_length)\n",
    "valid_data_batched = batchify(valid_data, batch_size, seq_length)\n",
    "test_data_batched = batchify(test_data, batch_size, seq_length)\n",
    "\n",
    "train_dataset = PTBDataset(train_data_batched.flatten(), seq_length)\n",
    "valid_dataset = PTBDataset(valid_data_batched.flatten(), seq_length)\n",
    "test_dataset = PTBDataset(test_data_batched.flatten(), seq_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-06T21:57:45.039441Z",
     "end_time": "2024-07-06T21:57:45.080168Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lstm model Architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        \"\"\"\n",
    "        :param input_size:\n",
    "        :param hidden_size:\n",
    "        :param num_layers:\n",
    "        :param num_classes:\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        # size of the hidden state\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # LSTM gates\n",
    "        # Forget gate\n",
    "        self.f_gate = nn.Sequential(\n",
    "            nn.Linear(input_size + hidden_size, hidden_size),\n",
    "            nn.Sigmoid() )\n",
    "\n",
    "        # Candidate gate(input modulation in the original paper)\n",
    "        self.g_gate = nn.Sequential(\n",
    "            nn.Linear(input_size + hidden_size, hidden_size),\n",
    "            nn.Tanh())\n",
    "\n",
    "        # Input gate\n",
    "        self.i_gate = nn.Sequential(\n",
    "            nn.Linear(input_size + hidden_size, hidden_size),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        # Output gate\n",
    "        self.o_gate = nn.Sequential(\n",
    "            nn.Linear(input_size + hidden_size,hidden_size),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self,x,h,c):\n",
    "        \"\"\"\n",
    "        :param x: input tensor\n",
    "        :param h: previous hidden state\n",
    "        :param c: previous cell state\n",
    "        :return: (c,h) tuple of new cell state and new hidden state\n",
    "        \"\"\"\n",
    "\n",
    "        # Concatenate input and hidden state\n",
    "        x_h = torch.cat((x,h),1)\n",
    "\n",
    "        # Forget\n",
    "        f = self.f_gate(x_h)\n",
    "        g = self.g_gate(x_h)\n",
    "        i = self.i_gate(x_h)\n",
    "        o = self.o_gate(x_h)\n",
    "\n",
    "        # update c\n",
    "        c = c * f + (g*i)\n",
    "        # THEN, update h\n",
    "        h = nn.Tanh(c) * o\n",
    "\n",
    "        return h,c\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
